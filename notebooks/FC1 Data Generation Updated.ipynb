{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19443,"status":"ok","timestamp":1650908596088,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"},"user_tz":240},"id":"Ny9HWwoxSM6i","outputId":"7e58d434-2a85-4d32-8e38-23d70e58fcc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":166,"status":"ok","timestamp":1650908613496,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"},"user_tz":240},"id":"4ajyvrD7R6Aj"},"outputs":[],"source":["import os\n","os.environ['HOME_DIR'] = 'drive/MyDrive/hidden-networks'\n","# !pip install -r $HOME_DIR/requirements.txt\n","\n","import sys\n","sys.path.append(os.path.join('/content', os.environ['HOME_DIR']))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pkngkPuoVh7E","executionInfo":{"status":"ok","timestamp":1650908619381,"user_tz":240,"elapsed":3648,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","import torch.autograd as autograd\n","import collections\n","\n","from supermask_pruning import GetSubnet, SupermaskConv, SupermaskLinear\n","from supermask_pruning import train, test\n","\n","class ArgClass:\n","    def __init__(self, args):\n","        self.setattrs(**args)\n","        \n","    def setattrs(self, **kwargs):\n","        for name, val in kwargs.items():\n","            setattr(self, name, val)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"e6xNej7l34ov","executionInfo":{"status":"ok","timestamp":1650908619517,"user_tz":240,"elapsed":141,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, args, input_channels, image_size, num_labels):\n","        super().__init__()\n","        \n","        sparsities = getattr(args, \"sparsity\", [{\"sparsity\": 1.0}, {\"sparsity\": 1.0}, {\"sparsity\": 1.0}, {\"sparsity\": 1.0}, {\"sparsity\": 1.0}])\n","        self.conv1 = SupermaskConv(input_channels, 64, 3, 1, bias=args.bias, init=args.init, **sparsities[0])\n","        self.conv2 = SupermaskConv(64, 64, 3, 1, bias=args.bias, init=args.init, **sparsities[1])\n","        s = (image_size - 4) * (image_size - 4) * 64 // 4\n","        self.fc1 = SupermaskLinear(s, 256, bias=args.bias, init=args.init, **sparsities[2])\n","        self.fc2 = SupermaskLinear(256, 256, bias=args.bias, init=args.init, **sparsities[3])\n","        self.fc3 = SupermaskLinear(256, num_labels, bias=args.bias, init=args.init, **sparsities[4])\n","        self.args = args\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.max_pool2d(x, 2)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output\n","    \n","    def get_extra_state(self):\n","        return self.args\n","      \n","    def set_extra_state(self, state):\n","        self.args = state"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YyHqlILxWd2m","executionInfo":{"status":"ok","timestamp":1650908619954,"user_tz":240,"elapsed":440,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"outputs":[],"source":["# The main function runs the full training loop on a dataset of your choice\n","def main(model_args, train_args, base_model=None, trial=None):\n","    args = ArgClass(model_args)\n","    train_args = ArgClass(train_args)\n","    dataset = args.dataset\n","\n","    use_cuda = not args.no_cuda and torch.cuda.is_available()\n","\n","    torch.manual_seed(args.seed)\n","\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    print(f\"Using device {device}\")\n","\n","    transform = None\n","    if dataset == \"MNIST\":\n","        transform = transforms.Compose([transforms.ToTensor(), \n","                                        transforms.Normalize((0.1307,), (0.3081,))\n","                                        ])\n","        train_transform = transform\n","        input_channels, image_size, num_labels = 1, 28, 10\n","    elif dataset == \"CIFAR10\":\n","        train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n","                                              transforms.RandomHorizontalFlip(),\n","                                              transforms.ToTensor(),\n","                                              transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","                                              ])\n","        transform = transforms.Compose([transforms.ToTensor(),\n","                                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","                                        ])\n","        input_channels, image_size, num_labels = 3, 32, 10\n","    else:\n","        raise ValueError(\"Only supported datasets are CIFAR10 and MNIST currently.\")\n","\n","    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","    train_loader = torch.utils.data.DataLoader(\n","        getattr(datasets, dataset)(os.path.join(train_args.data, dataset), \n","                                   train=True, download=True, transform=transform),\n","        batch_size=args.batch_size, shuffle=True, **kwargs)\n","    train_augmented_loader = torch.utils.data.DataLoader(\n","        getattr(datasets, dataset)(os.path.join(train_args.data, dataset), \n","                                   train=True, transform=train_transform),\n","        batch_size=args.batch_size, shuffle=True, **kwargs)\n","    test_loader = torch.utils.data.DataLoader(\n","        getattr(datasets, dataset)(os.path.join(train_args.data, dataset), \n","                                   train=False, transform=transform),\n","        batch_size=train_args.test_batch_size, shuffle=True, **kwargs)\n","\n","    model = Net(args, input_channels, image_size, num_labels).to(device)\n","\n","    if getattr(args, \"copy_layers\", None) is not None:\n","        if (bool(args.copy_layers) ^ (base_model is not None)):\n","            raise ValueError(\"copy_layers arg must be None or [] if base_model is not specified\")\n","        if base_model is not None and args.copy_layers:\n","            for layer in args.copy_layers:\n","                model.load_state_dict(getattr(base_model, layer).state_dict(prefix=f\"{layer}.\"), strict=False)\n","            \n","    # NOTE: only pass the parameters where p.requires_grad == True to the optimizer! Important!\n","    optimizer = getattr(optim, args.optimizer)(\n","        [p for p in model.parameters() if p.requires_grad],\n","        **args.optim_kwargs,\n","    )\n","    assert isinstance(args.epochs, list) or isinstance(args.epochs, int)\n","    num_epochs, check_freeze = (args.epochs, False) if isinstance(args.epochs, int) else (max(args.epochs), True)\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs) if args.scheduler else None \n","\n","    for epoch in range(1, num_epochs + 1):\n","        if check_freeze:\n","            for freeze_at_epoch, child in zip(args.epochs, model.children()):\n","                if freeze_at_epoch == epoch - 1:\n","                    child.freeze()\n","                    print(f\"Freezing {child} before epoch {epoch}\")\n","\n","        train(model, train_args.log_interval, device, train_augmented_loader, optimizer, criterion, epoch)\n","        if (train_args.train_eval_interval and epoch % train_args.train_eval_interval == 0) or (train_args.eval_on_last and epoch == args.epochs):\n","            train_acc, train_loss = test(model, device, criterion, train_loader, name=\"Train\")\n","            if trial:\n","                trial.set_user_attr('train_acc', {**trial.user_attrs.get('train_acc', {}), **{epoch: train_acc}})\n","                trial.set_user_attr('train_loss', {**trial.user_attrs.get('train_loss', {}), **{epoch: train_loss}})\n","        if (train_args.test_eval_interval and epoch % train_args.test_eval_interval == 0) or (train_args.eval_on_last and epoch == args.epochs):\n","            test_acc, test_loss = test(model, device, criterion, test_loader, name=\"Test\")\n","            if trial:\n","                trial.set_user_attr('test_acc', {**trial.user_attrs.get('test_acc', {}), **{epoch: test_acc}})\n","                trial.set_user_attr('test_loss', {**trial.user_attrs.get('test_loss', {}), **{epoch: test_loss}})\n","                trial.report(test_acc, epoch-1)\n","                if trial.should_prune():\n","                    raise optuna.exceptions.TrialPruned()\n","\n","        if scheduler:\n","            scheduler.step()\n","\n","    if args.save_name is not None:\n","        torch.save(model.state_dict(), os.path.join(os.environ['HOME_DIR'], \\\n","                                                    \"trained_networks\", args.save_name))\n","    \n","    return model, device, train_loader, test_loader, criterion\n","\n","def get_prune_mask(layer, sparsity):\n","    with torch.no_grad():\n","        return GetSubnet.apply(layer.scores.abs(), sparsity)\n","\n","def get_sign(weight):\n","  if weight > 0:\n","    return 1\n","  elif weight < 0:\n","    return -1\n","  else:\n","    return 0\n","\n","def process_weight(weight):\n","  return abs(weight).item(), get_sign(weight)\n","\n","def featurize_fc(weights, masks, sparsity, layer):\n","  weights = torch.transpose(weights, 0, 1)\n","  masks = torch.transpose(masks, 0, 1)\n","  weights_padded = F.pad(weights, (1,1,1,1), \"constant\", 0)\n","  data_fc = []\n","  for input in range(1, weights_padded.shape[0] - 1):\n","    for output in range(1, weights_padded.shape[1] - 1):\n","      mag_0, sign_0 = process_weight(weights_padded[input][output])\n","      mag_1, sign_1 = process_weight(weights_padded[input-1][output])\n","      mag_2, sign_2 = process_weight(weights_padded[input+1][output])\n","      mag_3, sign_3 = process_weight(weights_padded[input][output-1])\n","      mag_4, sign_4 = process_weight(weights_padded[input][output+1])\n","      include = masks[input-1][output-1].item()\n","      data_fc.append([input - 1, output - 1, mag_0, mag_1, mag_2, mag_3, mag_4, sign_0, sign_1, sign_2, sign_3, sign_4, sparsity, \"fc\"+layer, include])\n","  return data_fc\n","\n","\n","def featurize_conv(weights, masks, sparsity, layer):\n","  weights_padded =  F.pad(weights, (1,1,1,1), \"constant\", 0)\n","  data_conv = []\n","  for channel_num, channel in enumerate(weights_padded):\n","    for row in range(1, channel.shape[0] - 1):\n","      for col in range(1, channel.shape[1] - 1):\n","        mag_0, sign_0 = process_weight(channel[row][col])\n","        mag_1, sign_1 = process_weight(channel[row-1][col-1])\n","        mag_2, sign_2 = process_weight(channel[row-1][col])\n","        mag_3, sign_3 = process_weight(channel[row-1][col+1])\n","        mag_4, sign_4 = process_weight(channel[row][col-1])\n","        mag_5, sign_5 = process_weight(channel[row][col+1])\n","        mag_6, sign_6 = process_weight(channel[row+1][col-1])\n","        mag_7, sign_7 = process_weight(channel[row+1][col])\n","        mag_8, sign_8 = process_weight(channel[row+1][col+1])\n","        include = masks[channel_num][row-1][col-1].item()\n","        data_conv.append([channel_num, row - 1, col - 1, mag_0, mag_1, mag_2, mag_3, mag_4, mag_5, mag_6, mag_7, mag_8, sign_0, sign_1, sign_2, sign_3, sign_4, sign_5, sign_6, sign_7, sign_8, sparsity, \"conv\"+layer, include])\n","  return data_conv\n","\n","#dimension of input by output, out_channels by in_channels by kernel\n","def conv2_predictors(fc1_weights, conv2_masks, conv2_output_dim):\n","  data = torch.zeros([len(fc1_weights), len(fc1_weights[0])], dtype=torch.int32)\n","  flat_length = conv2_output_dim ** 2\n","  for i in range(len(conv2_masks)):\n","    shape = conv2_masks[i].shape\n","    #can replace pruned_count with some other function\n","    pruned_count = (shape[0] * shape[1] * shape[2]) - torch.count_nonzero(conv2_masks[i])\n","    data[i*flat_length:(i+1)*flat_length] = pruned_count\n","\n","  return data\n","\n","#dimension of input by output\n","def fc2_predictors(fc1_weights, fc2_masks):\n","  data = torch.zeros([len(fc1_weights), len(fc1_weights[0])], dtype=torch.int32)\n","  for j in range(len(fc1_weights[0])):\n","    pruned_count = len(fc2_masks[0]) - torch.count_nonzero(fc2_masks[j])\n","    data[:, j] = pruned_count\n","\n","  return data\n","\n","def make_pruned_df(conv2_mat, fc2_mat):\n","  i_list = [] \n","  j_list = [] \n","  c2_list = []\n","  fc2_list = []\n","\n","  for i in range(len(conv2_mat)):\n","    for j in range(len(conv2_mat[0])):\n","      i_list += [i]\n","      j_list += [j]\n","      c2_list += [conv2_mat[i][j].item()]\n","      fc2_list += [fc2_mat[i][j].item()]\n","  \n","  d = {'i': i_list, 'j': j_list, 'conv2_pruned_count': c2_list, 'fc2_pruned_count': fc2_list}\n","  return pd.DataFrame(data=d)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"AwL9v9H1qC89","executionInfo":{"status":"ok","timestamp":1650917499895,"user_tz":240,"elapsed":182,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"outputs":[],"source":["train_args = {\n","  \"test_batch_size\": 1000, # input batch size for testing (default: 1000)\n","  'data': '../data', # Location to store data (e.g. MNIST)\n","  'log_interval': 1000000, # how many batches to wait before logging training status\n","  'train_eval_interval': 20, # epoch interval at which to print training accuracy\n","  'test_eval_interval': 20, # epoch interval at which to print test accuracy\n","  'eval_on_last': True\n","}\n","\n","args = {\n","  \"dataset\": \"CIFAR10\",\n","  \"init\": \"kaiming_normal\",\n","  \"batch_size\": 64, # input batch size for training (default: 64)\n","  \"epochs\": 100, # number of epochs to train (default: 14)\n","  \"optimizer\": \"SGD\",\n","  \"optim_kwargs\": {\"lr\": 0.1, \"momentum\": 0.9, \"weight_decay\": 0.0005},\n","  \"scheduler\": True, # False for Adam, True for SGD, does CosineAnnealing\n","  'no_cuda': False, # disables CUDA training\n","  'seed': 1000, # random seed (default: 1)\n","  'save_name': None, # \"simple20_rs2\", # For Saving the current Model, None if not saving\n","  'sparsity': [{\"sparsity\": 0.5}, {\"sparsity\": 0.5}, {\"sparsity\": 0.5}, {\"sparsity\": 0.5}, {\"sparsity\": 0.5}], # 'how sparse is each layer'\n","  'copy_layers': [], # ['conv1', 'conv2', 'fc2'],\n","  'bias': False\n","}"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"iomeoIgeQFW9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650921278092,"user_tz":240,"elapsed":3776958,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}},"outputId":"c7daa2f2-6415-45b0-8d9b-9edb02719e7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device cuda\n","Files already downloaded and verified\n","Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.334862\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.488471\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.355451\n","Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.472837\n","Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.505441\n","Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.330603\n","Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.521719\n","Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.589324\n","Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.634306\n","Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.556131\n","Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.500636\n","Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.934933\n","Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.836945\n","Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.621260\n","Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.668438\n","Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.768890\n","Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.641572\n","Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.770273\n","Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.594961\n","Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.415243\n","\n","Train set: Average loss: 0.0243, Accuracy: 22781/50000 (46%)\n","\n","\n","Test set: Average loss: 0.0015, Accuracy: 4604/10000 (46%)\n","\n","Train Epoch: 21 [0/50000 (0%)]\tLoss: 1.931858\n","Train Epoch: 22 [0/50000 (0%)]\tLoss: 1.682474\n","Train Epoch: 23 [0/50000 (0%)]\tLoss: 1.867713\n","Train Epoch: 24 [0/50000 (0%)]\tLoss: 1.942140\n","Train Epoch: 25 [0/50000 (0%)]\tLoss: 1.638051\n","Train Epoch: 26 [0/50000 (0%)]\tLoss: 1.968875\n","Train Epoch: 27 [0/50000 (0%)]\tLoss: 1.433626\n","Train Epoch: 28 [0/50000 (0%)]\tLoss: 1.624351\n","Train Epoch: 29 [0/50000 (0%)]\tLoss: 1.498786\n","Train Epoch: 30 [0/50000 (0%)]\tLoss: 1.518912\n","Train Epoch: 31 [0/50000 (0%)]\tLoss: 1.608334\n","Train Epoch: 32 [0/50000 (0%)]\tLoss: 1.431739\n","Train Epoch: 33 [0/50000 (0%)]\tLoss: 1.194830\n","Train Epoch: 34 [0/50000 (0%)]\tLoss: 1.642828\n","Train Epoch: 35 [0/50000 (0%)]\tLoss: 1.707715\n","Train Epoch: 36 [0/50000 (0%)]\tLoss: 1.521526\n","Train Epoch: 37 [0/50000 (0%)]\tLoss: 1.512088\n","Train Epoch: 38 [0/50000 (0%)]\tLoss: 1.196284\n","Train Epoch: 39 [0/50000 (0%)]\tLoss: 1.641940\n","Train Epoch: 40 [0/50000 (0%)]\tLoss: 1.549386\n","\n","Train set: Average loss: 0.0227, Accuracy: 24856/50000 (50%)\n","\n","\n","Test set: Average loss: 0.0014, Accuracy: 5008/10000 (50%)\n","\n","Train Epoch: 41 [0/50000 (0%)]\tLoss: 1.270005\n","Train Epoch: 42 [0/50000 (0%)]\tLoss: 1.599414\n","Train Epoch: 43 [0/50000 (0%)]\tLoss: 1.673307\n","Train Epoch: 44 [0/50000 (0%)]\tLoss: 1.601545\n","Train Epoch: 45 [0/50000 (0%)]\tLoss: 1.664439\n","Train Epoch: 46 [0/50000 (0%)]\tLoss: 1.482975\n","Train Epoch: 47 [0/50000 (0%)]\tLoss: 1.426795\n","Train Epoch: 48 [0/50000 (0%)]\tLoss: 1.553507\n","Train Epoch: 49 [0/50000 (0%)]\tLoss: 1.547657\n","Train Epoch: 50 [0/50000 (0%)]\tLoss: 1.406679\n","Train Epoch: 51 [0/50000 (0%)]\tLoss: 1.280601\n","Train Epoch: 52 [0/50000 (0%)]\tLoss: 1.429479\n","Train Epoch: 53 [0/50000 (0%)]\tLoss: 1.389131\n","Train Epoch: 54 [0/50000 (0%)]\tLoss: 1.415737\n","Train Epoch: 55 [0/50000 (0%)]\tLoss: 1.414679\n","Train Epoch: 56 [0/50000 (0%)]\tLoss: 1.368898\n","Train Epoch: 57 [0/50000 (0%)]\tLoss: 1.392025\n","Train Epoch: 58 [0/50000 (0%)]\tLoss: 1.559119\n","Train Epoch: 59 [0/50000 (0%)]\tLoss: 1.719613\n","Train Epoch: 60 [0/50000 (0%)]\tLoss: 1.447919\n","\n","Train set: Average loss: 0.0205, Accuracy: 27050/50000 (54%)\n","\n","\n","Test set: Average loss: 0.0013, Accuracy: 5335/10000 (53%)\n","\n","Train Epoch: 61 [0/50000 (0%)]\tLoss: 1.459155\n","Train Epoch: 62 [0/50000 (0%)]\tLoss: 1.322366\n","Train Epoch: 63 [0/50000 (0%)]\tLoss: 1.611083\n","Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.963943\n","Train Epoch: 65 [0/50000 (0%)]\tLoss: 1.476409\n","Train Epoch: 66 [0/50000 (0%)]\tLoss: 1.545658\n","Train Epoch: 67 [0/50000 (0%)]\tLoss: 1.288462\n","Train Epoch: 68 [0/50000 (0%)]\tLoss: 1.283417\n","Train Epoch: 69 [0/50000 (0%)]\tLoss: 1.354434\n","Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.974868\n","Train Epoch: 71 [0/50000 (0%)]\tLoss: 1.019979\n","Train Epoch: 72 [0/50000 (0%)]\tLoss: 1.380734\n","Train Epoch: 73 [0/50000 (0%)]\tLoss: 1.396578\n","Train Epoch: 74 [0/50000 (0%)]\tLoss: 1.398652\n","Train Epoch: 75 [0/50000 (0%)]\tLoss: 1.141013\n","Train Epoch: 76 [0/50000 (0%)]\tLoss: 1.410213\n","Train Epoch: 77 [0/50000 (0%)]\tLoss: 0.801805\n","Train Epoch: 78 [0/50000 (0%)]\tLoss: 1.086929\n","Train Epoch: 79 [0/50000 (0%)]\tLoss: 1.131322\n","Train Epoch: 80 [0/50000 (0%)]\tLoss: 1.263062\n","\n","Train set: Average loss: 0.0157, Accuracy: 32649/50000 (65%)\n","\n","\n","Test set: Average loss: 0.0010, Accuracy: 6442/10000 (64%)\n","\n","Train Epoch: 81 [0/50000 (0%)]\tLoss: 1.057748\n","Train Epoch: 82 [0/50000 (0%)]\tLoss: 1.066070\n","Train Epoch: 83 [0/50000 (0%)]\tLoss: 1.100158\n","Train Epoch: 84 [0/50000 (0%)]\tLoss: 0.989035\n","Train Epoch: 85 [0/50000 (0%)]\tLoss: 0.974007\n","Train Epoch: 86 [0/50000 (0%)]\tLoss: 0.937403\n","Train Epoch: 87 [0/50000 (0%)]\tLoss: 1.180305\n","Train Epoch: 88 [0/50000 (0%)]\tLoss: 0.980871\n","Train Epoch: 89 [0/50000 (0%)]\tLoss: 1.104219\n","Train Epoch: 90 [0/50000 (0%)]\tLoss: 1.079076\n","Train Epoch: 91 [0/50000 (0%)]\tLoss: 1.001549\n","Train Epoch: 92 [0/50000 (0%)]\tLoss: 0.824172\n","Train Epoch: 93 [0/50000 (0%)]\tLoss: 0.775681\n","Train Epoch: 94 [0/50000 (0%)]\tLoss: 1.038993\n","Train Epoch: 95 [0/50000 (0%)]\tLoss: 1.107951\n","Train Epoch: 96 [0/50000 (0%)]\tLoss: 0.807265\n","Train Epoch: 97 [0/50000 (0%)]\tLoss: 0.894711\n","Train Epoch: 98 [0/50000 (0%)]\tLoss: 0.856926\n","Train Epoch: 99 [0/50000 (0%)]\tLoss: 0.805165\n","Train Epoch: 100 [0/50000 (0%)]\tLoss: 0.879881\n","\n","Train set: Average loss: 0.0124, Accuracy: 36677/50000 (73%)\n","\n","\n","Test set: Average loss: 0.0009, Accuracy: 7127/10000 (71%)\n","\n"]}],"source":["model, device, train_loader, test_loader, criterion = main(args, train_args, trial=None)"]},{"cell_type":"code","source":["import pickle\n","\n","sparsity = 0.5\n","conv1_masks = get_prune_mask(model.conv1, sparsity)\n","conv1_weights = model.conv1.weight\n","conv2_masks = get_prune_mask(model.conv2, sparsity)\n","conv2_weights = model.conv2.weight\n","fc1_masks = get_prune_mask(model.fc1, sparsity)\n","fc1_weights = model.fc1.weight\n","fc2_masks = get_prune_mask(model.fc2, sparsity)\n","fc2_weights = model.fc2.weight\n","\n","conv1_masks = conv1_masks.squeeze()\n","conv1_weights = conv1_weights.squeeze()\n","conv2_masks = conv2_masks.squeeze()\n","conv2_weights = conv2_weights.squeeze()\n","\n","data = {}\n","data[\"conv1\"] = torch.stack((conv1_masks, conv1_weights))\n","data[\"conv2\"] = torch.stack((conv2_masks, conv2_weights))\n","data[\"fc1\"] = torch.stack((fc1_masks, fc1_weights))\n","data[\"fc2\"] = torch.stack((fc2_masks, fc2_weights))\n","\n","def write_pickle(path, d):\n","  with open(path,'wb+') as f:\n","      return pickle.dump(d, f, protocol = pickle.HIGHEST_PROTOCOL)\n","\n","write_pickle('./drive/MyDrive/hidden-networks/dataset/conv1_s50_kaiming.pkl', data['conv1'])\n","write_pickle('./drive/MyDrive/hidden-networks/dataset/conv2_s50_kaiming.pkl', data['conv2'])\n","write_pickle('./drive/MyDrive/hidden-networks/dataset/fc1_s50_kaiming.pkl', data['fc1'])\n","write_pickle('./drive/MyDrive/hidden-networks/dataset/fc2_s50_kaiming.pkl', data['fc2'])\n","\n","fc1_data = featurize_fc(fc1_weights, fc1_masks, sparsity, \"1\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"0cvLPnmap7cI","executionInfo":{"status":"error","timestamp":1650921304650,"user_tz":240,"elapsed":26579,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}},"outputId":"34bd5bb1-5e8e-4d33-dc47-a69c96310c2d"},"execution_count":40,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-d932e78afea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mwrite_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./drive/MyDrive/hidden-networks/dataset/fc2_s50_kaiming.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mfc1_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeaturize_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-3afb75bd8b20>\u001b[0m in \u001b[0;36mfeaturize_fc\u001b[0;34m(weights, masks, sparsity, layer)\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m       \u001b[0mmag_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msign_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m       \u001b[0mmag_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msign_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0mmag_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msign_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-3afb75bd8b20>\u001b[0m in \u001b[0;36mprocess_weight\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeaturize_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-3afb75bd8b20>\u001b[0m in \u001b[0;36mget_sign\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_sign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","fc_df = pd.DataFrame(fc1_data, columns = ['i', 'j', 'mag_0', 'mag_1', 'mag_2', 'mag_3', 'mag_4', 'sign_0', 'sign_1', 'sign_2', 'sign_3', 'sign_4', 'sparsity', 'layer', 'include'])\n","\n","d1 = conv2_predictors(fc1_weights.T, conv2_masks, 12)\n","d2 = fc2_predictors(fc1_weights.T, fc2_masks.T)\n","pruned_fc_data = make_pruned_df(d1, d2)\n","\n","final_data = pd.merge(fc_df, pruned_fc_data, how='inner', left_on=['i','j'], right_on = ['i','j'])\n","# with open(\"./drive/MyDrive/hidden-networks/dataset/fc1_pruned_data.csv\", \"a+\", newline=\"\") as f:\n","#   writer = csv.writer(f)\n","#   writer.writerows(final_data)"],"metadata":{"id":"7KP-PKNdxBvn","executionInfo":{"status":"ok","timestamp":1650913956694,"user_tz":240,"elapsed":33665,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["final_data.to_csv('./drive/MyDrive/hidden-networks/dataset/fc1_pruned_data.csv')"],"metadata":{"id":"Z4RU7EG03fPB","executionInfo":{"status":"ok","timestamp":1650914198273,"user_tz":240,"elapsed":42372,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["final_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"ay3e6MsgIsxj","executionInfo":{"status":"ok","timestamp":1650914198653,"user_tz":240,"elapsed":18,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}},"outputId":"92f2af82-d3db-4367-f6f7-1bf56086c3ad"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   i  j     mag_0  mag_1     mag_2     mag_3     mag_4  sign_0  sign_1  \\\n","0  0  0  0.008929    0.0  0.008929  0.000000  0.008929       1       0   \n","1  0  1  0.008929    0.0  0.008929  0.008929  0.008929      -1       0   \n","2  0  2  0.008929    0.0  0.008929  0.008929  0.008929       1       0   \n","3  0  3  0.008929    0.0  0.008929  0.008929  0.008929      -1       0   \n","4  0  4  0.008929    0.0  0.008929  0.008929  0.008929       1       0   \n","\n","   sign_2  sign_3  sign_4  sparsity layer  include  conv2_pruned_count  \\\n","0       1       0      -1       0.5   fc1      1.0                 280   \n","1      -1       1       1       0.5   fc1      0.0                 280   \n","2      -1      -1      -1       0.5   fc1      1.0                 280   \n","3       1       1       1       0.5   fc1      1.0                 280   \n","4       1      -1      -1       0.5   fc1      1.0                 280   \n","\n","   fc2_pruned_count  \n","0               126  \n","1               118  \n","2               126  \n","3               136  \n","4               116  "],"text/html":["\n","  <div id=\"df-25ae5de7-359c-4946-a84f-1024129e8f48\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>mag_0</th>\n","      <th>mag_1</th>\n","      <th>mag_2</th>\n","      <th>mag_3</th>\n","      <th>mag_4</th>\n","      <th>sign_0</th>\n","      <th>sign_1</th>\n","      <th>sign_2</th>\n","      <th>sign_3</th>\n","      <th>sign_4</th>\n","      <th>sparsity</th>\n","      <th>layer</th>\n","      <th>include</th>\n","      <th>conv2_pruned_count</th>\n","      <th>fc2_pruned_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.008929</td>\n","      <td>0.0</td>\n","      <td>0.008929</td>\n","      <td>0.000000</td>\n","      <td>0.008929</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>0.5</td>\n","      <td>fc1</td>\n","      <td>1.0</td>\n","      <td>280</td>\n","      <td>126</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.008929</td>\n","      <td>0.0</td>\n","      <td>0.008929</td>\n","      <td>0.008929</td>\n","      <td>0.008929</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>fc1</td>\n","      <td>0.0</td>\n","      <td>280</td>\n","      <td>118</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.008929</td>\n","      <td>0.0</td>\n","      <td>0.008929</td>\n","      <td>0.008929</td>\n","      <td>0.008929</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>0.5</td>\n","      <td>fc1</td>\n","      <td>1.0</td>\n","      <td>280</td>\n","      <td>126</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0.008929</td>\n","      <td>0.0</td>\n","      <td>0.008929</td>\n","      <td>0.008929</td>\n","      <td>0.008929</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>fc1</td>\n","      <td>1.0</td>\n","      <td>280</td>\n","      <td>136</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.008929</td>\n","      <td>0.0</td>\n","      <td>0.008929</td>\n","      <td>0.008929</td>\n","      <td>0.008929</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>0.5</td>\n","      <td>fc1</td>\n","      <td>1.0</td>\n","      <td>280</td>\n","      <td>116</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25ae5de7-359c-4946-a84f-1024129e8f48')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-25ae5de7-359c-4946-a84f-1024129e8f48 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-25ae5de7-359c-4946-a84f-1024129e8f48');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["!pip install positional_encodings\n","from positional_encodings import PositionalEncoding1D, PositionalEncoding2D, PositionalEncoding3D\n","\n","p_enc_2d = PositionalEncoding2D(4)\n","y = torch.zeros((1,12,12,4))\n","mapper = p_enc_2d(y).squeeze()\n","\n","final_data['pos1'] = final_data.apply(lambda row: mapper[int((row.i % 144) / 12)][(row.i % 144) % 12][0].item(), axis=1)\n","final_data['pos2'] = final_data.apply(lambda row: mapper[int((row.i % 144) / 12)][(row.i % 144) % 12][1].item(), axis=1)\n","final_data['pos3'] = final_data.apply(lambda row: mapper[int((row.i % 144) / 12)][(row.i % 144) % 12][2].item(), axis=1)\n","final_data['pos4'] = final_data.apply(lambda row: mapper[int((row.i % 144) / 12)][(row.i % 144) % 12][3].item(), axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFbDW-gQMlW3","executionInfo":{"status":"ok","timestamp":1650916048866,"user_tz":240,"elapsed":1090042,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}},"outputId":"5cdad1fa-2657-4de9-cdb2-5360d744e1be"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting positional_encodings\n","  Downloading positional_encodings-5.0.0-py3-none-any.whl (7.3 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from positional_encodings) (1.21.6)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from positional_encodings) (2.8.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from positional_encodings) (1.11.0+cu113)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (1.6.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (1.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (3.17.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (57.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (0.24.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (2.8.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (2.8.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (1.44.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (0.2.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (13.0.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (0.5.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (4.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (3.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (3.3.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (1.0.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (1.14.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->positional_encodings) (1.1.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->positional_encodings) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->positional_encodings) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (0.6.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->positional_encodings) (3.2.0)\n","Installing collected packages: tf-estimator-nightly, positional-encodings\n","Successfully installed positional-encodings-5.0.0 tf-estimator-nightly-2.8.0.dev2021122109\n"]}]},{"cell_type":"code","source":["def conv2_norm(fc1_weights, conv2_weights, conv2_output_dim):\n","  data = torch.zeros([len(fc1_weights), len(fc1_weights[0])], dtype=torch.float32)\n","  flat_length = conv2_output_dim ** 2\n","  for i in range(len(conv2_weights)):\n","    #can replace pruned_count with some other function\n","    norm = torch.linalg.norm(conv2_weights[i])\n","    data[i*flat_length:(i+1)*flat_length] = norm\n","\n","  return data\n","\n","#dimension of input by output\n","def fc2_norm(fc1_weights, fc2_weights):\n","  data = torch.zeros([len(fc1_weights), len(fc1_weights[0])], dtype=torch.float32)\n","  for j in range(len(fc1_weights[0])):\n","    norm = torch.norm(fc2_weights[j])\n","    data[:, j] = norm\n","\n","  return data\n","\n","d1 = conv2_norm(fc1_weights.T, conv2_weights, 12)\n","d2 = fc2_norm(fc1_weights.T, fc2_weights.T)\n","norm_fc_data = make_pruned_df(d1, d2)\n","final_data = pd.merge(final_data, norm_fc_data, how='inner', left_on=['i','j'], right_on = ['i','j'])"],"metadata":{"id":"HlQoTKKlM2-8","executionInfo":{"status":"ok","timestamp":1650916316370,"user_tz":240,"elapsed":28273,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["final_data[\"fc2_pruned_count\"] = final_data['fc2_pruned_count_x']\n","final_data[\"conv2_pruned_count\"] = final_data['conv2_pruned_count_x']\n","final_data[\"fc2_norm\"] = final_data['fc2_pruned_count_y']\n","final_data[\"conv2_norm\"] = final_data['conv2_pruned_count_y']\n","\n","del final_data['fc2_pruned_count_x'], final_data['conv2_pruned_count_x'], final_data['fc2_pruned_count_y'], final_data['conv2_pruned_count_y']"],"metadata":{"id":"Ha4bZr8PN9y8","executionInfo":{"status":"ok","timestamp":1650916711860,"user_tz":240,"elapsed":346,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["final_data.to_csv('./drive/MyDrive/hidden-networks/dataset/fc1_pruned_data.csv')"],"metadata":{"id":"AC-X67cETgXi","executionInfo":{"status":"ok","timestamp":1650916785444,"user_tz":240,"elapsed":61426,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["final_data.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_M5_B9A6ULlc","executionInfo":{"status":"ok","timestamp":1650916904266,"user_tz":240,"elapsed":123,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}},"outputId":"3f7d6fd9-cd7e-412b-f572-cb860d999605"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['i', 'j', 'mag_0', 'mag_1', 'mag_2', 'mag_3', 'mag_4', 'sign_0',\n","       'sign_1', 'sign_2', 'sign_3', 'sign_4', 'sparsity', 'layer', 'include',\n","       'pos1', 'pos2', 'pos3', 'pos4', 'fc2_pruned_count',\n","       'conv2_pruned_count', 'fc2_norm', 'conv2_norm'],\n","      dtype='object')"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["import statsmodels.formula.api as smf\n","\n","log_reg = smf.logit(\"include ~ sign_0 + sign_1 + sign_2 + sign_3 + sign_4 + conv2_pruned_count + fc2_pruned_count + pos1 + pos2 + pos3 + pos4 + conv2_norm + fc2_norm\", data=final_data).fit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBrXC6YwNDsL","executionInfo":{"status":"ok","timestamp":1650916946006,"user_tz":240,"elapsed":11280,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}},"outputId":"d9024bf1-c2d0-4768-b661-d9e108f28aef"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimization terminated successfully.\n","         Current function value: 0.693055\n","         Iterations 5\n"]}]},{"cell_type":"code","source":["log_reg.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"id":"9u7Vy2E0T0m2","executionInfo":{"status":"ok","timestamp":1650916965103,"user_tz":240,"elapsed":2748,"user":{"displayName":"Neehal Tumma","userId":"16200375369847542065"}},"outputId":"6e613976-794c-4561-ab6a-f4b8e4f1f39a"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                           Logit Regression Results                           \n","==============================================================================\n","Dep. Variable:                include   No. Observations:              3211264\n","Model:                          Logit   Df Residuals:                  3211251\n","Method:                           MLE   Df Model:                           12\n","Date:                Mon, 25 Apr 2022   Pseudo R-squ.:               0.0001325\n","Time:                        20:02:44   Log-Likelihood:            -2.2256e+06\n","converged:                       True   LL-Null:                   -2.2259e+06\n","Covariance Type:            nonrobust   LLR p-value:                1.396e-118\n","======================================================================================\n","                         coef    std err          z      P>|z|      [0.025      0.975]\n","--------------------------------------------------------------------------------------\n","Intercept              0.1518   7.49e+04   2.03e-06      1.000   -1.47e+05    1.47e+05\n","sign_0                -0.0180      0.001    -16.125      0.000      -0.020      -0.016\n","sign_1                -0.0002      0.001     -0.172      0.864      -0.002       0.002\n","sign_2                 0.0003      0.001      0.304      0.761      -0.002       0.003\n","sign_3                 0.0006      0.001      0.523      0.601      -0.002       0.003\n","sign_4                 0.0010      0.001      0.863      0.388      -0.001       0.003\n","conv2_pruned_count    -0.0001   9.18e-05     -1.215      0.224      -0.000    6.84e-05\n","fc2_pruned_count      -0.0025      0.000    -16.748      0.000      -0.003      -0.002\n","pos1                  -0.0037      0.002     -2.311      0.021      -0.007      -0.001\n","pos2                  -0.0014      0.002     -0.907      0.365      -0.005       0.002\n","pos3                   0.0020      0.002      1.243      0.214      -0.001       0.005\n","pos4                  -0.0001      0.002     -0.077      0.939      -0.003       0.003\n","conv2_norm             0.0480      0.027      1.809      0.070      -0.004       0.100\n","fc2_norm               0.1518   7.49e+04   2.03e-06      1.000   -1.47e+05    1.47e+05\n","======================================================================================\n","\"\"\""],"text/html":["<table class=\"simpletable\">\n","<caption>Logit Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>        <td>include</td>     <th>  No. Observations:  </th>   <td>3211264</td>  \n","</tr>\n","<tr>\n","  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>3211251</td>  \n","</tr>\n","<tr>\n","  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    12</td>   \n","</tr>\n","<tr>\n","  <th>Date:</th>            <td>Mon, 25 Apr 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.0001325</td> \n","</tr>\n","<tr>\n","  <th>Time:</th>                <td>20:02:44</td>     <th>  Log-Likelihood:    </th> <td>-2.2256e+06</td>\n","</tr>\n","<tr>\n","  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-2.2259e+06</td>\n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.396e-118</td> \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>Intercept</th>          <td>    0.1518</td> <td> 7.49e+04</td> <td> 2.03e-06</td> <td> 1.000</td> <td>-1.47e+05</td> <td> 1.47e+05</td>\n","</tr>\n","<tr>\n","  <th>sign_0</th>             <td>   -0.0180</td> <td>    0.001</td> <td>  -16.125</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.016</td>\n","</tr>\n","<tr>\n","  <th>sign_1</th>             <td>   -0.0002</td> <td>    0.001</td> <td>   -0.172</td> <td> 0.864</td> <td>   -0.002</td> <td>    0.002</td>\n","</tr>\n","<tr>\n","  <th>sign_2</th>             <td>    0.0003</td> <td>    0.001</td> <td>    0.304</td> <td> 0.761</td> <td>   -0.002</td> <td>    0.003</td>\n","</tr>\n","<tr>\n","  <th>sign_3</th>             <td>    0.0006</td> <td>    0.001</td> <td>    0.523</td> <td> 0.601</td> <td>   -0.002</td> <td>    0.003</td>\n","</tr>\n","<tr>\n","  <th>sign_4</th>             <td>    0.0010</td> <td>    0.001</td> <td>    0.863</td> <td> 0.388</td> <td>   -0.001</td> <td>    0.003</td>\n","</tr>\n","<tr>\n","  <th>conv2_pruned_count</th> <td>   -0.0001</td> <td> 9.18e-05</td> <td>   -1.215</td> <td> 0.224</td> <td>   -0.000</td> <td> 6.84e-05</td>\n","</tr>\n","<tr>\n","  <th>fc2_pruned_count</th>   <td>   -0.0025</td> <td>    0.000</td> <td>  -16.748</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n","</tr>\n","<tr>\n","  <th>pos1</th>               <td>   -0.0037</td> <td>    0.002</td> <td>   -2.311</td> <td> 0.021</td> <td>   -0.007</td> <td>   -0.001</td>\n","</tr>\n","<tr>\n","  <th>pos2</th>               <td>   -0.0014</td> <td>    0.002</td> <td>   -0.907</td> <td> 0.365</td> <td>   -0.005</td> <td>    0.002</td>\n","</tr>\n","<tr>\n","  <th>pos3</th>               <td>    0.0020</td> <td>    0.002</td> <td>    1.243</td> <td> 0.214</td> <td>   -0.001</td> <td>    0.005</td>\n","</tr>\n","<tr>\n","  <th>pos4</th>               <td>   -0.0001</td> <td>    0.002</td> <td>   -0.077</td> <td> 0.939</td> <td>   -0.003</td> <td>    0.003</td>\n","</tr>\n","<tr>\n","  <th>conv2_norm</th>         <td>    0.0480</td> <td>    0.027</td> <td>    1.809</td> <td> 0.070</td> <td>   -0.004</td> <td>    0.100</td>\n","</tr>\n","<tr>\n","  <th>fc2_norm</th>           <td>    0.1518</td> <td> 7.49e+04</td> <td> 2.03e-06</td> <td> 1.000</td> <td>-1.47e+05</td> <td> 1.47e+05</td>\n","</tr>\n","</table>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":[""],"metadata":{"id":"gfggi4KXT1f9"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"FC1 Data Generation Updated.ipynb","provenance":[{"file_id":"1ulel-J7dj6zXXH2paZ5pVQbiScvlbgKQ","timestamp":1650854597501}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}